{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzVazZ0+4owXKwZx8Wo96S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ephraim19/AI-projects/blob/main/Imagetraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "aByf353RXnw7",
        "outputId": "ac95b5ac-f63e-4914-992f-284d4ce8b7f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Test Accuracy: 95.77000427246094\n",
            "Epoch 2, Test Accuracy: 97.15999603271484\n",
            "Epoch 3, Test Accuracy: 97.0999984741211\n",
            "Epoch 4, Test Accuracy: 97.39999389648438\n",
            "Epoch 5, Test Accuracy: 97.43999481201172\n",
            "Model: \"my_model_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          multiple                  320       \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        multiple                  0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            multiple                  2769024   \n",
            "                                                                 \n",
            " dense_41 (Dense)            multiple                  1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,770,634\n",
            "Trainable params: 2,770,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "Cloth description:  Trouser\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Load image from URL\n",
        "url = \"data:image/webp;base64,UklGRsYJAABXRUJQVlA4ILoJAADQKACdASqFAIUAPkkgjUSioiETal2wKASEs4Bq2GQWkCef7Dp3pvn73O7Rfs+nm7F+AF7C3bMAHzb+qFNE+ymEA8X/ueQD9y9Qr9eutf+6Ps1mjY4XWtcTwfH4JzDciVysqSzVicwKVfqUb8J/3l0x0Xdw/b+4G9t+/m3WAKnb9nRzX+5sWEOn1GAzShIVuoDB1GATRDi17EqX8wecc4jjXhByHl9B3Op5yUupgNUBuYj2vIsUAERyJKattnUW/2+PTQm0eVrzRukAC2Y/bpW7JbvPoaoOuC96WXhMxODLvS4wjreNv1EKdz+wbxy1p3hi0EEw9X+N0r+7uhGHo3DlHNcnvWzXtCTbIhHGCNhvopqJxJWUnc8jAJ7ogo3kZaFuUrFm+lldJ8lQfOtOvqomDweJ2+has3LuPf+maEqECdwLR02NXhkut3ccLrWqAAD+/daABcVYg+66Pe1gm//ehdTsUNfh/2t/z7u+BX4Dein7FrjrfnCYaUWVXecWmsESSt9SlVTxq/FDszmOXwy2KDe8+GqDo0qbrOb7WaEghaO91FBN/od0g7/NBIkeQpNACGVI1ORhygKAWGINeMKBtSr/BYvjNKIgA36m6k7YRUxoxowHYAT/0IJfcVYYfmIJQISeHkGp3BR+QCTWa9Z65oSw4UDZ/YyTFRDFJyI6ywjQPSgL9Za9nMUYUhIpwtO09BzL7kANRToB4lwrhzzIYPbo7bIZYsLd+ZcRXXDnXtCbdBHPHHCIfAre/ECLeC73iqnYLmFKy/Znt5UBc26rQdvGZPu2CMf0i6PvQjSqPmnA375GWbwL2HDri4HQwmBRHGhKl0P0b1ORyJXRuexS4btRMfzMTwvkHyvVILEnnqnBimBupswraj2HQH/Dvvng+S5mmYzW3e1k6WGsJue0V5tNdDB4S1niOoShn9sB4cQKJjGN6PvlGPEmyh8HiBG0qyxr3diE4xatm+ycu5UvuFmox4YY4skixmS/LkYDRy3S8CY6qsyaKL4CojpnGSY9FHNfl+lj+sLiO+yrcCJfhOML1lmwfgyJ9aUFity3HQBu38Zjvdf03AVRe3nXa5MbO4u0lbnXPmbqanK6uRTM+VcfPczO3heGr4c3N85z4lcGPT96A4D6NuAxkxxUEJ+pcTjPx+B/l7uGVHB348gFIXqZbZgsjh71YNqlG/La+bHNDqRT0b7/awiMoOypEV9YVldyptF+gpQae4DcN9l595n6uV/rbEpYmStmWz0AqkqvR8oznnS8FYkNxQ9YmpZHWxvwnMF85HpnorrBZoEez/y9bhl6gbq2ICKh//kRZ0+P+B8dNxRSMSxGi37bIWoeM4L5KIeXPbmod4YQgkgHfxTP0bJrxYo9B2Wx+smdiPDTRDk5TstxafqFZ99sRmvcmswfi79ZUl5jFczZtJ3W42/ewVBLH8TC5n30JjyNfmaQwZk7FQHrN98vs5Zx6iazXBOp9FVifJCzdoQVyRVTt9B3trjCgu69FjKxitjenqr+8a5EmS711KwIfufYOXWQdYsl1/F9P4SWjLGU6lZiY+7Esia/HuAo+Kv+hQinsfMTYfG62gaQ095rVru2if+4q525ZExPGWN5HHlLhL+bZ0dA+5oqQkT01NBI6CHoSFa5t6vdAqpHQ6OahXFLJ7zf6vbKoFdB+wsEvub7ga1QmACX41bZIOKHjwqHDPSd/9ynXILPOOyy3zIJwI6lg6Btm7GtRXOZ0vTFTYlYoBXT6KEU7x8P4leVeRVRaZdN4lD8iY8QLJ7/CISEuqYsJ4ZN49i5dEuLtQrCG0NXJRNpAyI3LNWaHkxM36nHCzokI5XWiWU1T2vAhrXGvyCW7n/fZOjf20AgT8powrD+J+ZGzIUwFqxO2885zUZnJLtguc2CDUjhQUhdVWzPXeiRNEIJt7y7F0pb/S3t1j0y2RwTwqUSAIq8F8HUPLoBjPPxOWGM5jB1bThWWu3LBE0y746ky3NmDDpfbBd0dwglVXnBfPvwepUHagGKBWaIf50i2RnIkTDpOpt5XqwoLengAGeo8BLtdwcUnryb1y2vrTIoqqv7hK8Kelizqyf7zt26bxpcxA59N5LrSqqQ8W1QBnmzdz29IHhbQWdErZZlWowFPE/aAiIV5TOVAfciHTOf4qeRfIorNxtfYq5prgxkcvJNwyctJq2ouHsLVTRFFAJb/wGBM/o9Q8/16+xOCJpfz1WEcgheuvouHf4SLI7RMlxC9AcP+op/ODZbNu4gTlfx73khi05kLO9Sc8YXeZW92PqtPKjZube8xVq4rXtG4GKBAu9piHRzGNr7G/rkYwOoK2+J24iP/n57qxbcyrCzeBsXJ7JuuME1rwiBsnJVoC7x71wB5VnbelMel7zvtbIMDqO2TP0Tk0WwgklG4hhmGZKRX9saVINZTUZU2df5a7csuLvdWqib62hWShUjuGd490iilf2fdBzNRQV8wHQa9Qk0rG9uAiYlbxidvBmgzqOErkJVoyUdlV1FdafqyTkKaPpdcgXRXlAMkj+U4ZZqw65hFjs0CuSzpA18x5eTZbEXNyJoByMYAGII/A+ytOkldB90vMentHJAav74l6pi6VfrMmrEM49iZpLXNwIFoNEfQ9HY1wNoOXj9d5zfHq/a6xTDw9ogvov6mBhyOSTLYRu+1Rvx6kEtmvAakxlD5f1+W7YGku117bUH1AUYdHsRMh8vwPVe7FvcKhjNK3/Byrl1D7UgeEWlyPY9ZE/MlI5ZVpS0xWdjlgEEezJUTprTVdI3I4OLS0F3W24P3JwMHJzoF7iPPErV24VoNlb5yE+/3+rsQALlPPPPnAjE7knV4i3wQbMKMZYz//3v4gnrlKTRGqBl/FrLmQiXv66cAvh5PFXJt+8xB0wv8Etnwd7NBmxhd/zK80QuYC1yv0+3IHE0pxRZuhSA9hROjoa9zUfUw8w3497OvDR7c5S7zJE/L8QkdEDfpdQOQNHJCZrZa2gOjDLQcFZf3MjCO9qkMX9zzbsiLBSqRzV3OknK2S9WWTmXb27mK9l6ufWFNZnZuP1y/NuCA1SxagedM4VwmIUcxobkrSe5jNt8fsYvKj27zgdskkIKQUhipYS/WJ73W9sQWshj4MouTrrCoG3C9PvMz71/0lq4RoD4WvMggU0sWpgw8dcla+2d++Q7tUeP9Pcb2qTODP16FmSxH/QE/f0QrDd582eFd3BL4wEcz/LiCCJgS7RWKEUbFudG/daNMQOmNO5+zGIitJ70pglQ/MfhflJ3g1fyu/Pq1jWy1VE0uIG2KOvGsFNN1SimDCIBonOHAAAAAAAAAAA=\"\n",
        "img_raw = keras.utils.get_file(\"image.jpg\", url)\n",
        "\n",
        "# Load your image and preprocess it\n",
        "img = keras.preprocessing.image.load_img(img_raw,target_size=(28,28))\n",
        "\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "# Convert image to grayscale using a formula\n",
        "gray_image = tf.math.reduce_mean(img_array, axis=-1, keepdims=True)\n",
        "\n",
        "img_array = tf.expand_dims(gray_image, 0)\n",
        "img_array = keras.applications.mobilenet.preprocess_input(img_array)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "class MyModel(Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10)\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = MyModel()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=True)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n",
        "\n",
        "EPOCHS = 7\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
        "  )\n",
        "\n",
        "# Map the class label to a description\n",
        "labels_map = {\n",
        "  0: 'T-shirt/top',\n",
        "  1: 'Trouser',\n",
        "  2: 'Pullover',\n",
        "  3: 'Dress',\n",
        "  4: 'Coat',\n",
        "  5: 'Sandal',\n",
        "  6: 'Shirt',\n",
        "  7: 'Sneaker',\n",
        "  8: 'Bag',\n",
        "  9: 'Ankle boot'\n",
        "}\n",
        "model.summary()\n",
        "# Use the model to make a prediction\n",
        "predictions = model.predict(img_array)\n",
        "# Get the class label with the highest probability\n",
        "label = tf.argmax(predictions, axis=1)\n",
        "# Print the predictions\n",
        "print(\"Cloth description: \", labels_map[int(label)])\n",
        "\n"
      ]
    }
  ]
}